import asyncio
from aiogram.fsm.context import FSMContext
from aiogram.types import Message
from aiogram.methods import SendChatAction
from ona.bot.state import DialogState
from ona.bot.prompt_template import build_prompt
from ona.bot.safety import detect_crisis, generate_crisis_response
from ona.bot.supabase_service import (
    save_user_data,
    append_dialog_history,
    get_user_data,
    bulk_save_user_data,  # ‚Üê –¥–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ PATCH
)
from ona.bot.core.openai_client import client
from ona.bot.analysis import generate_user_summary
from ona.bot.dialog_flow.phase_2_listen import grow_questions, reflective_listening
from ona.bot.dialog_flow.phase_3_emotions import (
    emotion_exploration,
    explore_emotion_meaning,
    reframe_thinking,
    analyze_emotion_and_thinking,
)
from ona.bot.dialog_flow.phase_4_solutions import explore_resources, collaborative_planning
from ona.bot.dialog_flow.phase_5_summary import summarize_insights
from ona.bot.utils.security import sanitize_user_input
from ona.bot.dialog_flow.phase_2_response import generate_phase_2_response  # –≤–≤–µ—Ä—Ö—É —Ñ–∞–π–ª–∞

PHASE_ORDER = [
    DialogState.phase_1_init,
    DialogState.phase_2_listen,
    DialogState.phase_3_emotions,
    DialogState.phase_4_solutions,
    DialogState.phase_5_summary,
]

GROW_SEQUENCE = ["goal", "reality", "options", "will"]


async def process_message(message: Message, state: FSMContext, user_input: str | None = None):
    user_id = message.from_user.id
    user_input = sanitize_user_input((user_input or message.text).strip())
    current_state = await state.get_state()
    user_data = get_user_data(user_id)

    if current_state is None:
        await state.set_state(DialogState.ask_name)
        await message.answer(
            "–ü—Ä–∏–≤–µ—Ç, –¥–æ—Ä–æ–≥–∞—è üåø\n"
            "–î–∞–≤–∞–π —Å–¥–µ–ª–∞–µ–º —Ç–µ–±–µ —É—é—Ç–Ω–æ–µ –º–µ—Å—Ç–æ –∑–¥–µ—Å—å ‚Äî –±—É–¥—Ç–æ –º—ã —Å–∏–¥–∏–º –Ω–∞ –∫—É—Ö–Ω–µ, –∞ –∏–∑ —á–∞–π–Ω–∏–∫–∞ –∏–¥—ë—Ç –ø–∞—Ä. "
            "–Ø —Ä—è–¥–æ–º, —á—Ç–æ–±—ã –≤—ã—Å–ª—É—à–∞—Ç—å, –ø–æ–Ω—è—Ç—å –∏ –±—ã—Ç—å —Å —Ç–æ–±–æ–π –Ω–∞ –æ–¥–Ω–æ–π –≤–æ–ª–Ω–µ.\n"
            "–ö–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç, —á—Ç–æ–±—ã —è –º–æ–≥–ª–∞ –æ–±—Ä–∞—â–∞—Ç—å—Å—è –ø–æ –∏–º–µ–Ω–∏?"
        )
        return

    if current_state == DialogState.ask_name.state:
        name = user_input  # Already sanitized
        save_user_data(user_id, "name", name)
        append_dialog_history(user_id, name, "user")
        greeting = generate_unique_greeting(name)
        context_question, options = generate_context_question()
        full_text = f"{greeting}\n\n{context_question}\n" + "\n".join(options)
        await state.update_data(last_options=[opt[3:].strip() for opt in options])
        append_dialog_history(user_id, full_text, "assistant")
        await message.bot(SendChatAction(chat_id=message.chat.id, action="typing"))
        await message.answer(full_text)
        await state.set_state(DialogState.phase_2_listen)
        save_user_data(user_id, "grow_step", "goal")
        save_user_data(user_id, "topic", "")
        return

    if detect_crisis(user_input):
        await state.set_state(DialogState.crisis)
        await message.answer(generate_crisis_response())
        return

    if current_state == DialogState.crisis.state:
        append_dialog_history(user_id, user_input, "user")
        history = get_dialog_history(user_id)
        prompt = (
            "–¢—ã ‚Äî –ò–ò-–ø–æ–º–æ—â–Ω–∏—Ü–∞. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ –∫—Ä–∏–∑–∏—Å–µ. "
            "–ì–æ–≤–æ—Ä–∏ –º—è–≥–∫–æ –∏ —Å –∑–∞–±–æ—Ç–æ–π. –ë–µ–∑ —Å–æ–≤–µ—Ç–æ–≤. –ë–µ–∑ —à–∞–±–ª–æ–Ω–æ–≤. –ë–µ–∑ –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏.\n\n"
            "–ò—Å—Ç–æ—Ä–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π:\n" +
            "\n".join([f"{m['role']}: {m['content']}" for m in history[-5:]])
        )
        response = generate_ai_response(prompt)
        append_dialog_history(user_id, response, "assistant")
        await message.answer(response)
        return

    if current_state == DialogState.completed.state:
        append_dialog_history(user_id, user_input, "user")

        summary = user_data.get("summary", "").strip()
        history = user_data.get("history", [])

        prompt = (
            "–¢—ã ‚Äî –∑–∞–±–æ—Ç–ª–∏–≤–∞—è AI-–ø–æ–¥—Ä—É–≥–∞, —Å –∫–æ—Ç–æ—Ä–æ–π –º–æ–∂–Ω–æ –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å –æ —á—ë–º —É–≥–æ–¥–Ω–æ. "
            "–¢—ã –Ω–µ —ç–∫—Å–ø–µ—Ä—Ç –∏ –Ω–µ –¥–∞—ë—à—å —Å–æ–≤–µ—Ç–æ–≤ ‚Äî —Ç—ã —Å–ª—É—à–∞–µ—à—å, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—à—å –∏ –≥–æ–≤–æ—Ä–∏—à—å –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏. "
            "–í–æ—Ç –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–≥–æ, —á—Ç–æ —É–∂–µ –æ–±—Å—É–∂–¥–∞–ª–æ—Å—å:\n"
            f"{summary}\n\n"
            "–í–æ—Ç –≤—ã–¥–µ—Ä–∂–∫–∞ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –º–µ–∂–¥—É –≤–∞–º–∏:\n" +
            "\n".join([f"{m['role'].capitalize()}: {m['content']}" for m in history[-20:]]) +
            "\n\n–û—Ç–≤–µ—Ç—å –∏—Å–∫—Ä–µ–Ω–Ω–µ, —Ç—ë–ø–ª–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ ‚Äî –±–µ–∑ —à–∞–±–ª–æ–Ω–æ–≤ –∏ –±–µ–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞. –ü—Ä–æ—Å—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä."
        )

        response = generate_ai_response(prompt)
        append_dialog_history(user_id, response, "assistant")
        await message.answer(response)
        return

    append_dialog_history(user_id, user_input, "user")
    phase = next((s for s in PHASE_ORDER if s.state == current_state), DialogState.phase_1_init)
    await message.bot(SendChatAction(chat_id=message.chat.id, action="typing"))

    if phase == DialogState.phase_2_listen:
        current_grow = user_data.get("grow_step", "goal")
        topic = user_data.get("topic", "")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π –æ—Ç–≤–µ—Ç
        save_user_data(user_id, f"grow_{current_grow}", user_input)

        # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤–∞—è —Ñ—Ä–∞–∑–∞ ‚Üí –∑–∞–ø–æ–º–∏–Ω–∞–µ–º –∫–∞–∫ —Ç–µ–º—É
        if current_grow == "goal" and not topic:
            save_user_data(user_id, "topic", user_input)
            topic = user_input

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ grow-–æ—Ç–≤–µ—Ç—ã
        answers = {}
        for step in GROW_SEQUENCE:
            val = user_data.get(f"grow_{step}")
            if val:
                answers[step] = val

        question_block, options = generate_phase_2_response(user_input, topic, current_grow, answers)
        text = f"{question_block}\n" + "\n".join(options)
        await state.update_data(last_options=[opt[3:].strip() for opt in options])
        append_dialog_history(user_id, text, "assistant")
        await message.answer(text)

        # –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç–∞–¥–∏–∏ GROW –∏–ª–∏ –∫ —Ñ–∞–∑–µ 3
        idx = GROW_SEQUENCE.index(current_grow)
        if idx + 1 < len(GROW_SEQUENCE):
            save_user_data(user_id, "grow_step", GROW_SEQUENCE[idx + 1])
            await state.set_state(DialogState.phase_2_listen)
        else:
            save_user_data(user_id, "grow_step", None)
            save_user_data(user_id, "emotion_step", "start")
            await state.set_state(DialogState.phase_3_emotions)
        return

    if phase == DialogState.phase_3_emotions:
        emotion_step = user_data.get("emotion_step", "start")

        if emotion_step == "start":
            result = analyze_emotion_and_thinking(user_id, user_input)
            if result == "emotion":
                save_user_data(user_id, "emotion_step", "meaning")
                question, options = emotion_exploration()
                text = f"–Ø –≤–∏–∂—É, —ç—Ç–æ –æ—á–µ–Ω—å –≤–∞–∂–Ω–æ –¥–ª—è —Ç–µ–±—è. –≠—Ç–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è –Ω–∞ —Ç–∞–∫—É—é —Å–∏—Ç—É–∞—Ü–∏—é.\n\n{question}\n" + "\n".join(options)
                await state.update_data(last_options=[opt[3:].strip() for opt in options])
                append_dialog_history(user_id, text, "assistant")
                await message.answer(text)
                return
            elif result == "distortion":
                save_user_data(user_id, "emotion_step", "cognitive_1")
                blocks = reframe_thinking()
                question, options = blocks[0]
                text = f"{question}\n" + "\n".join(options)
                append_dialog_history(user_id, text, "assistant")
                await message.answer(text)
                return
            else:
                await state.set_state(DialogState.phase_4_solutions)
                save_user_data(user_id, "resource_step", "resources")
                topic = user_data.get("topic", "")
                history = [m["content"] for m in get_dialog_history(user_id) if m["role"] == "user"]
                questions = explore_resources(topic, history)
                question, options = questions[0]
                text = f"{question}\n" + "\n".join(options)
                append_dialog_history(user_id, text, "assistant")
                await message.answer(text)
                return

        elif emotion_step == "meaning":
            save_user_data(user_id, "emotion_step", "done")
            question, options = explore_emotion_meaning()
            text = f"{question}\n" + "\n".join(options)
            await state.update_data(last_options=[opt[3:].strip() for opt in options])
            append_dialog_history(user_id, text, "assistant")
            await message.answer(text)
            return

        elif emotion_step == "cognitive_1":
            save_user_data(user_id, "emotion_step", "cognitive_2")
            blocks = reframe_thinking()
            question, options = blocks[1]
            text = f"{question}\n" + "\n".join(options)
            await state.update_data(last_options=[opt[3:].strip() for opt in options])
            append_dialog_history(user_id, text, "assistant")
            await message.answer(text)
            return

        elif emotion_step == "cognitive_2":
            save_user_data(user_id, "emotion_step", "done")
            blocks = reframe_thinking()
            question, options = blocks[2]
            text = f"{question}\n" + "\n".join(options)
            append_dialog_history(user_id, text, "assistant")
            await message.answer(text)
            return

        else:
            await state.set_state(DialogState.phase_4_solutions)
            save_user_data(user_id, "resource_step", "resources")
            topic = user_data.get("topic", "")
            history = [m["content"] for m in get_dialog_history(user_id) if m["role"] == "user"]
            questions = explore_resources(topic, history)
            question, options = questions[0]
            text = f"{question}\n" + "\n".join(options)
            await state.update_data(last_options=[opt[3:].strip() for opt in options])
            append_dialog_history(user_id, text, "assistant")
            await message.answer(text)
            return

    if phase == DialogState.phase_4_solutions:
        current_resource = user_data.get("resource_step", "resources")
        topic = user_data.get("topic", "")
        history = [m["content"] for m in get_dialog_history(user_id) if m["role"] == "user"]

        if current_resource == "resources":
            save_user_data(user_id, "resource_step", "plan_1")
            questions = explore_resources(topic, history)
            question, options = questions[0]
            text = f"{question}\n" + "\n".join(options)
            append_dialog_history(user_id, text, "assistant")
            await message.answer(text)
            return

        elif current_resource == "plan_1":
            save_user_data(user_id, "resource_step", "plan_2")
            questions = collaborative_planning(topic, history)
            question, options = questions[0]
            text = f"{question}\n" + "\n".join(options)
            await state.update_data(last_options=[opt[3:].strip() for opt in options])
            append_dialog_history(user_id, text, "assistant")
            await message.answer(text)
            return

        elif current_resource == "plan_2":
            await state.set_state(DialogState.phase_5_summary)
            questions = collaborative_planning(topic, history)
            question, options = questions[1]
            text = f"{question}\n" + "\n".join(options)
            await state.update_data(last_options=[opt[3:].strip() for opt in options])
            append_dialog_history(user_id, text, "assistant")
            await message.answer(text)
            return

    if phase == DialogState.phase_5_summary:
        topic = user_data.get("topic", "")
        history = [m["content"] for m in get_dialog_history(user_id)]
        question_block, support_lines = summarize_insights(topic, history)

        options = [line[3:].strip() for line in question_block.splitlines() if line.strip().startswith(("A)", "B)", "C)", "D)"))]
        if options:
            await state.update_data(last_options=options) 
        append_dialog_history(user_id, question_block, "assistant")
        await message.answer(question_block)

        await state.update_data(summary_support="\n".join(support_lines))
        await state.set_state(DialogState.summary_answer)
        return

    if current_state == DialogState.summary_answer.state:
        append_dialog_history(user_id, user_input, "user")
        topic = user_data.get("topic", "")
        history = [m["content"] for m in get_dialog_history(user_id) if m["role"] == "user"]
        data = await state.get_data()
        support_text = data.get("summary_support", "").replace('"', '').strip()

        summary = f"–ì–ª–∞–≤–Ω–∞—è —Ç–µ–º–∞: {topic}\n\n–í—ã–≤–æ–¥—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n" + "\n".join(history[-3:])
        save_user_data(user_id, "summary", summary)
        save_user_data(user_id, "profile", "done")
        
        final_message = f"{support_text}\n\n–ï—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî –º–æ–∂–µ–º –ø—Ä–æ—Å—Ç–æ –ø–æ–±–æ–ª—Ç–∞—Ç—å –¥–∞–ª—å—à–µ."
        append_dialog_history(user_id, final_message, "assistant")
        await message.answer(final_message)

        await state.set_state(DialogState.completed)
        generate_user_summary(user_id)
        return

    history = get_dialog_history(user_id)
    prompt = build_prompt(history, phase.state)
    response = generate_ai_response(prompt)
    append_dialog_history(user_id, response, "assistant")
    await message.answer(response)


def generate_unique_greeting(name: str) -> str:
    prompt = f"""
–¢—ã ‚Äî AI-–ø–æ–º–æ—â–Ω–∏—Ü–∞, –ø–æ–¥—Ä—É–≥–∞ –ø–æ –ø–µ—Ä–µ–ø–∏—Å–∫–µ. –ö —Ç–µ–±–µ –æ–±—Ä–∞—â–∞–µ—Ç—Å—è –¥–µ–≤—É—à–∫–∞ –ø–æ –∏–º–µ–Ω–∏ {name}, —É –∫–æ—Ç–æ—Ä–æ–π –º–æ–∂–µ—Ç –±—ã—Ç—å —Ç—Ä–µ–≤–æ–≥–∞, —Å–æ–º–Ω–µ–Ω–∏—è, —Ç—è–∂–µ—Å—Ç—å –≤–Ω—É—Ç—Ä–∏.

–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–æ—Ä–æ—Ç–∫–æ–µ (1‚Äì3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –≤ —Å—Ç–∏–ª–µ –ø–∏—Å–∞—Ç–µ–ª—å–Ω–∏—Ü—ã –∏–∑ –ù—å—é-–ô–æ—Ä–∫ –¢–∞–π–º—Å.  
–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤—ã—Ä–∞–∑–∏:
- –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –ø–æ–º–æ—á—å –±–µ–∑ –æ—Å—É–∂–¥–µ–Ω–∏—è
- –∞—Ç–º–æ—Å—Ñ–µ—Ä—É —Ç–µ–ø–ª–∞ –∏ –ø—Ä–∏–Ω—è—Ç–∏—è
- —Å—Ç–∏–ª—å ‚Äî –Ω–µ –∫–∞–∫ –æ—Ç–∫—Ä—ã—Ç–∫–∞, –∞ –∫–∞–∫ –¥—É—à–µ–≤–Ω—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä –º–µ–∂–¥—É –±–ª–∏–∑–∫–∏–º–∏

–§–æ—Ä–º–∞—Ç:
- –î–æ 250 —Å–∏–º–≤–æ–ª–æ–≤
- –û–±—Ä–∞—â–µ–Ω–∏–µ –Ω–∞ "—Ç—ã"
- –ë–µ–∑ –∫–ª–∏—à–µ –∏ –ø–∞—Ñ–æ—Å–∞
- –í–∫–ª—é—á–∏ –º—è–≥–∫–æ–µ –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏–µ –ø–æ–¥–µ–ª–∏—Ç—å—Å—è
"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "system", "content": prompt}],
        temperature=0.85,
        max_tokens=150,
    )
    return response.choices[0].message.content.strip()


def generate_context_question() -> tuple[str, list[str]]:
    prompt = """
–¢—ã ‚Äî AI-–Ω–∞—Å—Ç–∞–≤–Ω–∏—Ü–∞, –ø–æ–¥—Ä—É–≥–∞, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–º–æ–≥–∞–µ—Ç –¥–µ–≤—É—à–∫–µ —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è –≤ –µ—ë —á—É–≤—Å—Ç–≤–∞—Ö. 
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –º—è–≥–∫–æ —Å–ø—Ä–æ—Å–∏—Ç—å, –æ —á—ë–º –æ–Ω–∞ —Ö–æ—á–µ—Ç –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å.

–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π:
- –æ–¥–∏–Ω –∫–æ—Ä–æ—Ç–∫–∏–π, —Ç—ë–ø–ª—ã–π –≤–æ–ø—Ä–æ—Å (1 —Å—Ç—Ä–æ–∫–∞, –Ω–∞ "—Ç—ã")
- 4 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –æ—Ç–≤–µ—Ç–∞ A‚ÄìD (–¥–æ 10 —Å–ª–æ–≤ –∫–∞–∂–¥—ã–π), —Ç–æ–∂–µ –Ω–∞ "—Ç—ã", –±–µ–∑ —Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–µ–π

–í–∞—Ä–∏–∞–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Å—É—Ç—å:
A ‚Äî –±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ  
B ‚Äî —Å–∏—Ç—É–∞—Ü–∏—è  
C ‚Äî –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫–µ  
D ‚Äî —Å–≤–æ–π –≤–∞—Ä–∏–∞–Ω—Ç  

–§–æ—Ä–º–∞—Ç:
–í–æ–ø—Ä–æ—Å: [—Ç–µ–∫—Å—Ç]
A) ...
B) ...
C) ...
D) ...
"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "system", "content": prompt}],
        temperature=0.7,
        max_tokens=200,
    )
    lines = response.choices[0].message.content.strip().splitlines()
    question = lines[0].replace("–í–æ–ø—Ä–æ—Å:", "").strip()
    options = lines[1:5]
    return question, options


def get_dialog_history(user_id: int) -> list:
    return get_user_data(user_id).get("history", [])


def generate_ai_response(prompt: str) -> str:
    completion = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "system", "content": prompt}],
        temperature=0.8,
        max_tokens=500,
    )
    return completion.choices[0].message.content.strip()
